{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2 - Visi√≥n por Computadora\n",
    "## Ejercicio 2\n",
    "## Integrantes:\n",
    "\n",
    "- Javier Alvarado - 21188\n",
    "- Mario Guerra - 21008\n",
    "- Emilio Solano - 21212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-pythonNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script isympy.exe is installed in 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.10.21-cp310-cp310-win_amd64.whl (51.0 MB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp310-cp310-win_amd64.whl (204.2 MB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "Collecting numpy>=1.21.2\n",
      "  Downloading numpy-2.2.4-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Collecting sounddevice>=0.4.4\n",
      "  Downloading sounddevice-0.5.1-py3-none-win_amd64.whl (363 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl (991 kB)\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl (46.2 MB)\n",
      "Collecting jax\n",
      "  Downloading jax-0.5.3-py3-none-any.whl (2.4 MB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "Collecting jaxlib\n",
      "  Downloading jaxlib-0.5.3-cp310-cp310-win_amd64.whl (65.8 MB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Collecting attrs>=19.1.0\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Collecting protobuf<5,>=4.25.3\n",
      "  Downloading protobuf-4.25.6-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\usuario\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.13.1)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Collecting sympy==1.13.1\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Collecting CFFI>=1.0\n",
      "  Downloading cffi-1.17.1-cp310-cp310-win_amd64.whl (181 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Collecting scipy>=1.11.1\n",
      "  Downloading scipy-1.15.2-cp310-cp310-win_amd64.whl (41.2 MB)\n",
      "Collecting ml_dtypes>=0.4.0\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-win_amd64.whl (209 kB)\n",
      "Collecting opt_einsum\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-win_amd64.whl (218 kB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-win_amd64.whl (71 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\usuario\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->mediapipe) (24.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.57.0-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Installing collected packages: numpy, scipy, pycparser, mpmath, ml-dtypes, MarkupSafe, sympy, pyparsing, pillow, opt-einsum, networkx, kiwisolver, jinja2, jaxlib, fsspec, fonttools, filelock, cycler, contourpy, CFFI, torch, sounddevice, sentencepiece, protobuf, opencv-contrib-python, matplotlib, jax, flatbuffers, attrs, absl-py, torchvision, opencv-python, mediapipe\n",
      "Successfully installed CFFI-1.17.1 MarkupSafe-3.0.2 absl-py-2.2.2 attrs-25.3.0 contourpy-1.3.1 cycler-0.12.1 filelock-3.18.0 flatbuffers-25.2.10 fonttools-4.57.0 fsspec-2025.3.2 jax-0.5.3 jaxlib-0.5.3 jinja2-3.1.6 kiwisolver-1.4.8 matplotlib-3.10.1 mediapipe-0.10.21 ml-dtypes-0.5.1 mpmath-1.3.0 networkx-3.4.2 numpy-1.26.4 opencv-contrib-python-4.11.0.86 opencv-python-4.11.0.86 opt-einsum-3.4.0 pillow-11.1.0 protobuf-4.25.6 pycparser-2.22 pyparsing-3.2.3 scipy-1.15.2 sentencepiece-0.2.0 sounddevice-0.5.1 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n",
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python mediapipe torch torchvision\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "!cd yolov5\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "yolo_path = \"c:/Users/Usuario/OneDrive/Documentos/U/A√±o 5/Ciclo 1/Visi√≥n/Object_detectorVC/yolov5\"\n",
    "os.chdir(yolo_path)\n",
    "\n",
    "if yolo_path not in sys.path:\n",
    "    sys.path.append(yolo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2025-4-9 Python-3.10.0 torch-2.6.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# üìÅ Ruta donde est√° tu carpeta clonada de YOLOv5\n",
    "yolo_path = \"c:/Users/Usuario/OneDrive/Documentos/U/A√±o 5/Ciclo 1/Visi√≥n/Object_detectorVC/yolov5\"\n",
    "os.chdir(yolo_path)\n",
    "if yolo_path not in sys.path:\n",
    "    sys.path.append(yolo_path)\n",
    "\n",
    "# ‚úÖ Importaciones desde YOLOv5\n",
    "from yolov5.models.common import DetectMultiBackend\n",
    "from yolov5.utils.general import non_max_suppression, scale_boxes\n",
    "from yolov5.utils.torch_utils import select_device\n",
    "from yolov5.utils.augmentations import letterbox\n",
    "\n",
    "# üîß Inicializar YOLOv5\n",
    "device = select_device('')\n",
    "model = DetectMultiBackend('./yolov5s.pt', device=device)\n",
    "model.eval()\n",
    "\n",
    "# üï∫ Inicializar MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# üìπ Cargar el video\n",
    "input_path = \"../assets/danceVideo.mp4\"\n",
    "cap = cv2.VideoCapture(input_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# üé• Inicializar salidas\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_pose = cv2.VideoWriter(\"../assets/silhouette_dance_video.mp4\", fourcc, fps, (width, height))\n",
    "out_black = cv2.VideoWriter(\"../assets/silhouette_dance_black.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "# üîÅ Procesar video frame por frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    original = frame.copy()\n",
    "    black_frame = np.zeros_like(frame)\n",
    "\n",
    "    # üìè Preparar frame para YOLOv5\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = letterbox(img, new_shape=640)[0]\n",
    "    img_yolo = torch.from_numpy(img_resized).permute(2, 0, 1).float().to(device) / 255.0\n",
    "    img_yolo = img_yolo.unsqueeze(0)\n",
    "\n",
    "    # üß† Inferencia con YOLO\n",
    "    pred = model(img_yolo)\n",
    "    pred = non_max_suppression(pred, conf_thres=0.5, classes=[0])  # clase 0 = persona\n",
    "\n",
    "    for det in pred:\n",
    "        if det is not None and len(det):\n",
    "            det[:, :4] = scale_boxes(img_resized.shape[:2], det[:, :4], frame.shape).round()\n",
    "\n",
    "            for *xyxy, conf, cls in det:\n",
    "                x1, y1, x2, y2 = map(int, xyxy)\n",
    "                person_roi = frame[y1:y2, x1:x2]\n",
    "                if person_roi.size == 0:\n",
    "                    continue\n",
    "\n",
    "                # üßç Estimar pose de la persona detectada\n",
    "                person_rgb = cv2.cvtColor(person_roi, cv2.COLOR_BGR2RGB)\n",
    "                result = pose.process(person_rgb)\n",
    "\n",
    "                if result.pose_landmarks:\n",
    "                    # Dibujar puntos y conexiones SOLO de esta persona, en un frame temporal\n",
    "                    person_silhouette = np.zeros_like(frame)\n",
    "\n",
    "                    # Convertir landmarks al espacio del frame original\n",
    "                    pose_landmarks = result.pose_landmarks\n",
    "\n",
    "                    # Ajustar coordenadas al contexto de toda la imagen (no solo ROI)\n",
    "                    for idx, landmark in enumerate(pose_landmarks.landmark):\n",
    "                        landmark.x = x1 / width + landmark.x * (x2 - x1) / width\n",
    "                        landmark.y = y1 / height + landmark.y * (y2 - y1) / height\n",
    "\n",
    "                    # Dibujar en el frame original\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=original,\n",
    "                        landmark_list=pose_landmarks,\n",
    "                        connections=mp_pose.POSE_CONNECTIONS,\n",
    "                        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                        connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)\n",
    "                    )\n",
    "\n",
    "                    # Dibujar en el frame temporal (solo una persona)\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=person_silhouette,\n",
    "                        landmark_list=pose_landmarks,\n",
    "                        connections=mp_pose.POSE_CONNECTIONS,\n",
    "                        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=2),\n",
    "                        connection_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)\n",
    "                    )\n",
    "\n",
    "                    # Sumar esta silueta individual al frame final\n",
    "                    black_frame = cv2.add(black_frame, person_silhouette)\n",
    "\n",
    "\n",
    "    out_pose.write(original)\n",
    "    out_black.write(black_frame)\n",
    "\n",
    "# üßπ Liberar recursos\n",
    "cap.release()\n",
    "out_pose.release()\n",
    "out_black.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
